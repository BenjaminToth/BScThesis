{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLdm2ekwV1Wo"
      },
      "source": [
        "# Setup:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azhPkV9JV1Wp"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install tqdm\n",
        "!pip install matplotlib\n",
        "!pip install numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quFn0Qi4oWgD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "import torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path to data from drive"
      ],
      "metadata": {
        "id": "K9JBaI4s1PjS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqY_5386ox06"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "image_path = Path(\"Path\")\n",
        "train_path = image_path / \"train\"\n",
        "train_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformation settings"
      ],
      "metadata": {
        "id": "EYZAyEKk1M-8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_RsMi7tox5O"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.RandomRotation((0,10)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomResizedCrop(size=(64, 64), scale=(0.9, 1.0)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=train_path,\n",
        "                                  transform=data_transform,\n",
        "                                  target_transform=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample image with transformations"
      ],
      "metadata": {
        "id": "8AewyT831JVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "image, label = train_data[i][0], train_data[i][1]\n",
        "\n",
        "image_array = image.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image_array)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x8ife8HAD9_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch setting"
      ],
      "metadata": {
        "id": "0hkhmav41GIs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz9qFGNEV1Wr"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=2,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models setup"
      ],
      "metadata": {
        "id": "Irz3RsGz1C9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,latent_space_size = 100,\n",
        "               ngf = 64,\n",
        "               n_channel = 3):\n",
        "\n",
        "    super(Generator,self).__init__()\n",
        "\n",
        "    self.generator = nn.Sequential(\n",
        "            nn.ConvTranspose2d( latent_space_size, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf, n_channel, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "  def forward(self,inp):\n",
        "    return self.generator(inp)\n",
        "\n",
        "G = Generator()\n",
        "G\n",
        "x = torch.randn((1, 100, 1, 1))\n",
        "G(x).shape"
      ],
      "metadata": {
        "id": "Ez5E9dPR9PbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,n_channel = 3,\n",
        "               ndf = 64):\n",
        "    super(Discriminator,self).__init__()\n",
        "\n",
        "    self.discriminator = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(n_channel, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "  @staticmethod\n",
        "  def linear_block(in_ftrs,out_ftrs,p):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_ftrs,out_ftrs),\n",
        "        nn.BatchNorm1d(out_ftrs),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self,inp):\n",
        "    return self.discriminator(inp)\n",
        "\n",
        "\n",
        "D = Discriminator()\n",
        "D(G(x)).shape"
      ],
      "metadata": {
        "id": "Q7RYBwcO9Uzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you can load a trained models"
      ],
      "metadata": {
        "id": "GpkwM-XO091Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_PATH_D = Path(r\"discriminator_path\")\n",
        "LOAD_PATH_G = Path(r\"generator_path\")\n",
        "\n",
        "G.load_state_dict(torch.load(LOAD_PATH_G))\n",
        "D.load_state_dict(torch.load(LOAD_PATH_D))"
      ],
      "metadata": {
        "id": "ENrShCvaqGLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS_oRSpGV1Ws"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoutsJMNV1Wt"
      },
      "outputs": [],
      "source": [
        "G.to(device)\n",
        "D.to(device)\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 64\n",
        "epochs = 10000\n",
        "fixed_noise = torch.randn((1, 100, 1, 1))\n",
        "\n",
        "opt_generator = optim.Adam(G.parameters(), lr=LEARNING_RATE)\n",
        "opt_discriminator = optim.Adam(D.parameters(), lr=LEARNING_RATE)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "G.train()\n",
        "D.train()\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        real = X\n",
        "        noise = torch.randn(BATCH_SIZE, 100, 1, 1).to(device)\n",
        "        fake = G(noise)\n",
        "\n",
        "\n",
        "        disc_real = D(real).reshape(-1)\n",
        "        loss_disc_real = loss_fn(disc_real, torch.ones_like(disc_real))\n",
        "        disc_fake = D(fake.detach()).reshape(-1)\n",
        "        loss_disc_fake = loss_fn(disc_fake, torch.zeros_like(disc_fake))\n",
        "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
        "        D.zero_grad()\n",
        "        loss_disc.backward()\n",
        "        opt_discriminator.step()\n",
        "\n",
        "        output = D(fake).reshape(-1)\n",
        "        loss_gen = loss_fn(output, torch.ones_like(output))\n",
        "        G.zero_grad()\n",
        "        loss_gen.backward()\n",
        "        opt_generator.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "tDEty1AW00V3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ploting a sample of the Generator output"
      ],
      "metadata": {
        "id": "FvvNRo7N03If"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e85l8xrVV1Wt"
      },
      "outputs": [],
      "source": [
        "G.to(\"cpu\")\n",
        "G.eval()\n",
        "noise = torch.randn(1, 100, 1, 1)\n",
        "image = G(noise)\n",
        "image = image.squeeze()\n",
        "\n",
        "image_array = image.permute(1, 2, 0).detach().numpy()\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image_array)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(image.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "cVVWvdwN3xGY",
        "z8KY4qjo9Lvx"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}