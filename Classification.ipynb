{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBVvVUbdcyn2"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEhLhQot8oQP"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIkeiH2k8Zzn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torchinfo\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "from torchvision import models\n",
        "from google.colab import drive\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you need to set up the path to the train and test folder."
      ],
      "metadata": {
        "id": "FqIZu2entZjB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGEKvIQVEecP"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "image_path = Path(\"Path\")\n",
        "train_path = image_path / \"train\"\n",
        "test_path = image_path / \"test\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformations setting"
      ],
      "metadata": {
        "id": "yZpRLJ2Itn6U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmof8HYccWs0"
      },
      "outputs": [],
      "source": [
        "data_transform_1 = transforms.Compose([\n",
        "    transforms.RandomRotation((0,360)),\n",
        "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=.2,contrast=.1, saturation=.2, hue=.1),\n",
        "    transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1.0)),\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data_transform_2 = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data_transform_3 = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.RandomRotation((90,90)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data_transform_4 = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.RandomRotation((180,180)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data_transform_5 = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.RandomRotation((270,270)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=train_path,\n",
        "                                  transform=data_transform_1,\n",
        "                                  target_transform=None)\n",
        "\n",
        "test_data_1 = datasets.ImageFolder(root=test_path,\n",
        "                                   transform=data_transform_2)\n",
        "\n",
        "test_data_2 = datasets.ImageFolder(root=test_path,\n",
        "                                   transform=data_transform_3)\n",
        "\n",
        "test_data_3 = datasets.ImageFolder(root=test_path,\n",
        "                                   transform=data_transform_4)\n",
        "\n",
        "test_data_4 = datasets.ImageFolder(root=test_path,\n",
        "                                   transform=data_transform_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader setting"
      ],
      "metadata": {
        "id": "njMu4pcGuVVV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbInUcsIc_EA"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=2,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader_1 = DataLoader(dataset=test_data_1,\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               num_workers=2,\n",
        "                               shuffle=True)\n",
        "\n",
        "test_dataloader_2 = DataLoader(dataset=test_data_2,\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               num_workers=2,\n",
        "                               shuffle=True)\n",
        "\n",
        "test_dataloader_3 = DataLoader(dataset=test_data_3,\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               num_workers=2,\n",
        "                               shuffle=True)\n",
        "\n",
        "test_dataloader_4 = DataLoader(dataset=test_data_4,\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               num_workers=2,\n",
        "                               shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you can load a trained model"
      ],
      "metadata": {
        "id": "y5eF15zMuNsh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpOfCokb8Zzr"
      },
      "outputs": [],
      "source": [
        "LOAD_PATH = Path(\"Path\")\n",
        "\n",
        "model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
        "model.fc = nn.Linear(in_features=2048, out_features=30, bias=True)\n",
        "\n",
        "model.load_state_dict(torch.load(LOAD_PATH))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this if you dont have a trained model"
      ],
      "metadata": {
        "id": "Njoj8e44uaki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
        "model.fc = nn.Linear(in_features=2048, out_features=30, bias=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "_wBEUOOlBEZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a summary of the models structure"
      ],
      "metadata": {
        "id": "6SewR6QDuttP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=[1, 3, 224, 224])"
      ],
      "metadata": {
        "id": "o15yr522BHHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "9T_5fhj5v2_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing optimizer and loss function and scheduler for weights"
      ],
      "metadata": {
        "id": "LQaMtbQsuyNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.794)\n",
        "train_loss, train_acc = 0, 0\n",
        "model.train()"
      ],
      "metadata": {
        "id": "mKq1OysrSP3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jOmSpu68Zzs"
      },
      "outputs": [],
      "source": [
        "s_num = 0\n",
        "epochs = 50\n",
        "\n",
        "l1 = []\n",
        "l2 = []\n",
        "l3 = []\n",
        "l4 = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    train_loss_list = []\n",
        "    train_acc_list = []\n",
        "    test_loss_list = []\n",
        "    test_acc_list = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    #i = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "\n",
        "        #print(i)\n",
        "        #i += 32\n",
        "\n",
        "        # Send data to GPU\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # 6. Accuracy calculation\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    train_loss = train_loss / len(train_dataloader)\n",
        "    train_acc = train_acc / len(train_dataloader)\n",
        "    train_loss_list.append(train_loss)\n",
        "    train_acc_list.append(train_acc)\n",
        "\n",
        "    # Test\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for test_dataloader in test_dataloader_list:\n",
        "\n",
        "            test_loss, test_acc = 0, 0\n",
        "\n",
        "            for batch, (X, y) in enumerate(test_dataloader):\n",
        "\n",
        "                # Send data to target device\n",
        "                X, y = X.to(device), y.to(device)\n",
        "\n",
        "                # 1. Forward pass\n",
        "                test_pred_logits = model(X)\n",
        "\n",
        "                # 2. Calculate and accumulate loss\n",
        "                loss = loss_fn(test_pred_logits, y)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                # Calculate and accumulate accuracy\n",
        "                test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "                test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "            test_loss = test_loss / len(test_dataloader)\n",
        "            test_acc = test_acc / len(test_dataloader)\n",
        "\n",
        "            test_loss_list.append(test_loss)\n",
        "            test_acc_list.append(test_acc)\n",
        "\n",
        "    l1.append(train_loss_list[0])\n",
        "    l2.append(train_acc_list[0])\n",
        "    l3.append(sum(test_loss_list)/len(test_loss_list))\n",
        "    l4.append(sum(test_acc_list)/len(test_acc_list))\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # 1. Create models directory\n",
        "    MODEL_PATH = Path(\"Path\")\n",
        "    MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 2. Create model save path\n",
        "    MODEL_NAME = \"Name\" + str(s_num) #Saves after every epoch\n",
        "    MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "    # 3. Save the model state dict\n",
        "    print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "    torch.save(obj=model.state_dict(),\n",
        "               f=MODEL_SAVE_PATH)\n",
        "    s_num += 1\n",
        "\n",
        "print(\"Train Loss\", train_loss_list)\n",
        "print(\"Train Acc\", train_acc_list)\n",
        "print(\"Test Loss\", sum(test_loss_list)/len(test_loss_list))\n",
        "print(\"Test Acc\", sum(test_acc_list)/len(test_acc_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NJDkP198Zzs"
      },
      "source": [
        "# Testing:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a confusion matrix and testing with that"
      ],
      "metadata": {
        "id": "Ze5a3RN4wp_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = []\n",
        "for i in range(30):\n",
        "    m = []\n",
        "    for j in range(30):\n",
        "        m.append(0)\n",
        "    M.append(m)"
      ],
      "metadata": {
        "id": "LzCpWBEriYio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_data_1"
      ],
      "metadata": {
        "id": "Gt5D5t4hjnmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ive5haDy8Zzt"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "class_names = train_data.classes\n",
        "pred_dict = {element: 0 for element in class_names}\n",
        "\n",
        "\n",
        "for i in tqdm(range(len(test_data))):\n",
        "    image, label = test_data[i][0], test_data[i][1]\n",
        "\n",
        "    sample = torch.unsqueeze(image, dim=0).to(device)\n",
        "    pred_logit = model(sample)\n",
        "    pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "    pred_list = list(pred_prob.cpu())\n",
        "    pred_label = pred_list.index(max(pred_list))\n",
        "\n",
        "    M[label][pred_label] += 1\n",
        "\n",
        "    if pred_label == label:\n",
        "        pred_dict[class_names[label]] += 1\n",
        "\n",
        "print(pred_dict)\n",
        "\n",
        "total_sum = 0\n",
        "\n",
        "for value in pred_dict.values():\n",
        "    total_sum += value\n",
        "\n",
        "print(total_sum)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in M:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "fylJ681xjQbG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2Uro1Ot28Zzu",
        "g5k-gx2yFg5i"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}